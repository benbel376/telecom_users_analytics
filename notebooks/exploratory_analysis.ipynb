{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d3711a0-1b94-486e-b1de-8ce6db1297cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing essential libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import warnings\n",
    "from pandasql import sqldf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "80ed930e-0af2-4455-9741-93d88329afb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# supressing warning messages\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f1bdeeb-dbd8-41a8-8e56-f09357241a4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bearer Id</th>\n",
       "      <th>Start</th>\n",
       "      <th>Start ms</th>\n",
       "      <th>End</th>\n",
       "      <th>End ms</th>\n",
       "      <th>Dur. (ms)</th>\n",
       "      <th>IMSI</th>\n",
       "      <th>MSISDN/Number</th>\n",
       "      <th>IMEI</th>\n",
       "      <th>Last Location Name</th>\n",
       "      <th>...</th>\n",
       "      <th>Youtube DL (Bytes)</th>\n",
       "      <th>Youtube UL (Bytes)</th>\n",
       "      <th>Netflix DL (Bytes)</th>\n",
       "      <th>Netflix UL (Bytes)</th>\n",
       "      <th>Gaming DL (Bytes)</th>\n",
       "      <th>Gaming UL (Bytes)</th>\n",
       "      <th>Other DL (Bytes)</th>\n",
       "      <th>Other UL (Bytes)</th>\n",
       "      <th>Total UL (Bytes)</th>\n",
       "      <th>Total DL (Bytes)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.311448e+19</td>\n",
       "      <td>4/4/2019 12:01</td>\n",
       "      <td>770.0</td>\n",
       "      <td>4/25/2019 14:35</td>\n",
       "      <td>662.0</td>\n",
       "      <td>1823652.0</td>\n",
       "      <td>2.082014e+14</td>\n",
       "      <td>3.366496e+10</td>\n",
       "      <td>3.552121e+13</td>\n",
       "      <td>9.16457E+15</td>\n",
       "      <td>...</td>\n",
       "      <td>15854611.0</td>\n",
       "      <td>2501332.0</td>\n",
       "      <td>8198936.0</td>\n",
       "      <td>9656251.0</td>\n",
       "      <td>278082303.0</td>\n",
       "      <td>14344150.0</td>\n",
       "      <td>171744450.0</td>\n",
       "      <td>8814393.0</td>\n",
       "      <td>36749741.0</td>\n",
       "      <td>308879636.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.311448e+19</td>\n",
       "      <td>4/9/2019 13:04</td>\n",
       "      <td>235.0</td>\n",
       "      <td>4/25/2019 8:15</td>\n",
       "      <td>606.0</td>\n",
       "      <td>1365104.0</td>\n",
       "      <td>2.082019e+14</td>\n",
       "      <td>3.368185e+10</td>\n",
       "      <td>3.579401e+13</td>\n",
       "      <td>L77566A</td>\n",
       "      <td>...</td>\n",
       "      <td>20247395.0</td>\n",
       "      <td>19111729.0</td>\n",
       "      <td>18338413.0</td>\n",
       "      <td>17227132.0</td>\n",
       "      <td>608750074.0</td>\n",
       "      <td>1170709.0</td>\n",
       "      <td>526904238.0</td>\n",
       "      <td>15055145.0</td>\n",
       "      <td>53800391.0</td>\n",
       "      <td>653384965.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.311448e+19</td>\n",
       "      <td>4/9/2019 17:42</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4/25/2019 11:58</td>\n",
       "      <td>652.0</td>\n",
       "      <td>1361762.0</td>\n",
       "      <td>2.082003e+14</td>\n",
       "      <td>3.376063e+10</td>\n",
       "      <td>3.528151e+13</td>\n",
       "      <td>D42335A</td>\n",
       "      <td>...</td>\n",
       "      <td>19725661.0</td>\n",
       "      <td>14699576.0</td>\n",
       "      <td>17587794.0</td>\n",
       "      <td>6163408.0</td>\n",
       "      <td>229584621.0</td>\n",
       "      <td>395630.0</td>\n",
       "      <td>410692588.0</td>\n",
       "      <td>4215763.0</td>\n",
       "      <td>27883638.0</td>\n",
       "      <td>279807335.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.311448e+19</td>\n",
       "      <td>4/10/2019 0:31</td>\n",
       "      <td>486.0</td>\n",
       "      <td>4/25/2019 7:36</td>\n",
       "      <td>171.0</td>\n",
       "      <td>1321509.0</td>\n",
       "      <td>2.082014e+14</td>\n",
       "      <td>3.375034e+10</td>\n",
       "      <td>3.535661e+13</td>\n",
       "      <td>T21824A</td>\n",
       "      <td>...</td>\n",
       "      <td>21388122.0</td>\n",
       "      <td>15146643.0</td>\n",
       "      <td>13994646.0</td>\n",
       "      <td>1097942.0</td>\n",
       "      <td>799538153.0</td>\n",
       "      <td>10849722.0</td>\n",
       "      <td>749039933.0</td>\n",
       "      <td>12797283.0</td>\n",
       "      <td>43324218.0</td>\n",
       "      <td>846028530.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.311448e+19</td>\n",
       "      <td>4/12/2019 20:10</td>\n",
       "      <td>565.0</td>\n",
       "      <td>4/25/2019 10:40</td>\n",
       "      <td>954.0</td>\n",
       "      <td>1089009.0</td>\n",
       "      <td>2.082014e+14</td>\n",
       "      <td>3.369980e+10</td>\n",
       "      <td>3.540701e+13</td>\n",
       "      <td>D88865A</td>\n",
       "      <td>...</td>\n",
       "      <td>15259380.0</td>\n",
       "      <td>18962873.0</td>\n",
       "      <td>17124581.0</td>\n",
       "      <td>415218.0</td>\n",
       "      <td>527707248.0</td>\n",
       "      <td>3529801.0</td>\n",
       "      <td>550709500.0</td>\n",
       "      <td>13910322.0</td>\n",
       "      <td>38542814.0</td>\n",
       "      <td>569138589.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Bearer Id            Start  Start ms              End  End ms  \\\n",
       "0  1.311448e+19   4/4/2019 12:01     770.0  4/25/2019 14:35   662.0   \n",
       "1  1.311448e+19   4/9/2019 13:04     235.0   4/25/2019 8:15   606.0   \n",
       "2  1.311448e+19   4/9/2019 17:42       1.0  4/25/2019 11:58   652.0   \n",
       "3  1.311448e+19   4/10/2019 0:31     486.0   4/25/2019 7:36   171.0   \n",
       "4  1.311448e+19  4/12/2019 20:10     565.0  4/25/2019 10:40   954.0   \n",
       "\n",
       "   Dur. (ms)          IMSI  MSISDN/Number          IMEI Last Location Name  \\\n",
       "0  1823652.0  2.082014e+14   3.366496e+10  3.552121e+13        9.16457E+15   \n",
       "1  1365104.0  2.082019e+14   3.368185e+10  3.579401e+13            L77566A   \n",
       "2  1361762.0  2.082003e+14   3.376063e+10  3.528151e+13            D42335A   \n",
       "3  1321509.0  2.082014e+14   3.375034e+10  3.535661e+13            T21824A   \n",
       "4  1089009.0  2.082014e+14   3.369980e+10  3.540701e+13            D88865A   \n",
       "\n",
       "   ...  Youtube DL (Bytes)  Youtube UL (Bytes)  Netflix DL (Bytes)  \\\n",
       "0  ...          15854611.0           2501332.0           8198936.0   \n",
       "1  ...          20247395.0          19111729.0          18338413.0   \n",
       "2  ...          19725661.0          14699576.0          17587794.0   \n",
       "3  ...          21388122.0          15146643.0          13994646.0   \n",
       "4  ...          15259380.0          18962873.0          17124581.0   \n",
       "\n",
       "   Netflix UL (Bytes)  Gaming DL (Bytes)  Gaming UL (Bytes)  Other DL (Bytes)  \\\n",
       "0           9656251.0        278082303.0         14344150.0       171744450.0   \n",
       "1          17227132.0        608750074.0          1170709.0       526904238.0   \n",
       "2           6163408.0        229584621.0           395630.0       410692588.0   \n",
       "3           1097942.0        799538153.0         10849722.0       749039933.0   \n",
       "4            415218.0        527707248.0          3529801.0       550709500.0   \n",
       "\n",
       "   Other UL (Bytes)  Total UL (Bytes)  Total DL (Bytes)  \n",
       "0         8814393.0        36749741.0       308879636.0  \n",
       "1        15055145.0        53800391.0       653384965.0  \n",
       "2         4215763.0        27883638.0       279807335.0  \n",
       "3        12797283.0        43324218.0       846028530.0  \n",
       "4        13910322.0        38542814.0       569138589.0  \n",
       "\n",
       "[5 rows x 55 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# locating the data\n",
    "parent_dir = os.path.abspath(os.path.join(os.getcwd(), os.pardir))\n",
    "data_path = os.path.join(parent_dir,\"data\",\"test.csv\")\n",
    "\n",
    "#loading the data\n",
    "df = pd.read_csv(data_path)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "969a36e7-ab67-4033-ad8b-287fa1421632",
   "metadata": {},
   "outputs": [],
   "source": [
    "# looking at available features\n",
    "df.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc9f1ce-71fb-4d3c-935f-d9fbea1a1544",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating percentages of missing values in each column \n",
    "def calculateMissing(df):\n",
    "    df2 = df.isna().sum().to_frame().reset_index()\n",
    "    df2.rename(columns = {'index':'variables', 0:'count'}, inplace = True)\n",
    "    df2['percent'] = round(df2['count']*100/df.shape[0])\n",
    "    data_type_lis = df.dtypes.to_frame().reset_index()\n",
    "    df2['data_type'] = data_type_lis.iloc[:,1]\n",
    "    \n",
    "    unique_val = []\n",
    "    for i in range(df2.shape[0]):\n",
    "        unique_val.append(len(pd.unique(df[df2.iloc[i,0]])))\n",
    "    df2['unique_values'] = pd.Series(unique_val)\n",
    "    return df2\n",
    "\n",
    "calculateMissing(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5412a81-a821-4814-ba63-38cec327a4dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "'rdx_session','start','start_ms','end','end_ms','rdx_dur','sim_id','phone_number','device_id','last_location','avg_rtt_dl','avg_rtt_ul','avg_bearer_tp_dl','avg_bearer_tp_ul','tcp_dl_retrans_(Bytes)','tcp_ul_retrans_(Bytes)','DL TP < 50 Kbps (%)','50 Kbps < DL TP < 250 Kbps (%)','250 Kbps < DL TP < 1 Mbps (%)','DL TP > 1 Mbps (%)','UL TP < 10 Kbps (%)','10 Kbps < UL TP < 50 Kbps (%)','50 Kbps < UL TP < 300 Kbps (%)','UL TP > 300 Kbps (%)','http_dl_(Bytes)','http_ul_(Bytes)','activity_dur_dl','activity_dur_ul','Dur. (ms).1','handset_manu','handset_type','Nb of sec with 125000B < Vol DL','Nb of sec with 1250B < Vol UL < 6250B','Nb of sec with 31250B < Vol DL < 125000B','Nb of sec with 37500B < Vol UL','Nb of sec with 6250B < Vol DL < 31250B','Nb of sec with 6250B < Vol UL < 37500B','Nb of sec with Vol DL < 6250B','Nb of sec with Vol UL < 1250B','social_dl_(Bytes)','social_ul_(Bytes)','google_dl_(Bytes)','google_ul_(Bytes)','email_dl_(Bytes)','email_ul_(Bytes)','youtube_dl_(Bytes)','youtube_ul_(Bytes)','netflix_dl_(Bytes)','netflix_ul_(Bytes)','gaming_dl_(Bytes)','gaming_ul_(Bytes)','other_dl_(Bytes)','other_ul_(Bytes)','total_ul_(Bytes)','total_dl_(Bytes)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f43f371b-6a1f-4ee7-85c5-3f5db9f4e1f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#selecting some useful columns\n",
    "drop_lis = ['start','start_ms','end','end_ms','DL TP < 50 Kbps (%)','50 Kbps < DL TP < 250 Kbps (%)','250 Kbps < DL TP < 1 Mbps (%)','DL TP > 1 Mbps (%)','UL TP < 10 Kbps (%)','10 Kbps < UL TP < 50 Kbps (%)','50 Kbps < UL TP < 300 Kbps (%)','UL TP > 300 Kbps (%)''Nb of sec with 125000B < Vol DL','Nb of sec with 1250B < Vol UL < 6250B','Nb of sec with 31250B < Vol DL < 125000B','Nb of sec with 37500B < Vol UL','Nb of sec with 6250B < Vol DL < 31250B','Nb of sec with 6250B < Vol UL < 37500B','Nb of sec with Vol DL < 6250B','Nb of sec with Vol UL < 1250B']\n",
    "df_s = df[df.columns[~df.columns.isin(drop_lis)]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9dfee56-7aae-429e-8a55-0da9fff9b00c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#droping columns with more than 30% missing values.\n",
    "df3 = df.drop(df.columns[[14, 15, 24, 25, 31, 32, 33, 34, 35, 36]], axis=1) \n",
    "calculateMissing(df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be6131c3-14ec-4cdb-841a-f51585afe61b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#filling missing values of categorical variables with mode \n",
    "def fill_missing_by_mode(df, cols):\n",
    "    mod_fill_list = []\n",
    "    for i in range(cols.shape[0]):\n",
    "        if(cols.iloc[i,3] == \"object\"):\n",
    "            mod_fill_list.append(cols.iloc[i,0])\n",
    "            \n",
    "    for col in mod_fill_list:\n",
    "        df[col] = df[col].fillna(df[col].mode()[0])\n",
    "    return df\n",
    "\n",
    "df3 = fill_missing_by_mode(df3, calculateMissing(df3))\n",
    "\n",
    "calculateMissing(df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40021e74-b46e-4cf3-a815-dd35aa0d344f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_missing_ffill(df, cols):\n",
    "    for col in cols:\n",
    "        df[col] = df[col].fillna(method='ffill')\n",
    "    return df\n",
    "\n",
    "def fill_missing_by_median(df, cols):\n",
    "    median_fill_list = []\n",
    "\n",
    "    for i in range(cols.shape[0]):\n",
    "        if(cols.iloc[i,3] == \"float64\"):\n",
    "            median_fill_list.append(cols.iloc[i,0])\n",
    "            \n",
    "    for col in median_fill_list:\n",
    "        df[col] = df[col].fillna(df[col].median())\n",
    "    return df\n",
    "\n",
    "def fill_missing_by_mean(df, cols):\n",
    "    mean_fill_list = []\n",
    "    for i in range(cols.shape[0]):\n",
    "        if(cols.iloc[i,3] == \"float64\"):\n",
    "            mean_fill_list.append(cols.iloc[i,0])\n",
    "    \n",
    "    for col in mean_fill_list:\n",
    "        df[col] = df[col].fillna(df[col].median())\n",
    "    return df\n",
    "\n",
    "df3 = fill_missing_by_median(df3, calculateMissing(df3))\n",
    "                  \n",
    "\n",
    "\n",
    "calculateMissing(df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc743360-8998-4676-b4a8-b2bd149226ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "679b63c8-ad43-4904-bd6c-ce3f75bd81d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing duplicate users\n",
    "df3 = df3.drop_duplicates()\n",
    "calculateMissing(df3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "906b66ba-143e-4b99-963b-1b777bcfe1b2",
   "metadata": {},
   "source": [
    "<h1>Querying using sql</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1905056-164c-4f0f-b6d4-367569e04283",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a querying function.\n",
    "queryDf = lambda q: sqldf(q, globals())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bdcb4fe6-c6c9-4370-b1ea-6b466c506110",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   Handset Type  user_count\n",
      "0              Huawei B528S-23A       19752\n",
      "1       Apple iPhone 6S (A1688)        9419\n",
      "2        Apple iPhone 6 (A1586)        9023\n",
      "3        Apple iPhone 7 (A1778)        6326\n",
      "4       Apple iPhone Se (A1723)        5187\n",
      "5        Apple iPhone 8 (A1905)        4993\n",
      "6       Apple iPhone Xr (A2105)        4568\n",
      "7  Samsung Galaxy S8 (Sm-G950F)        4520\n",
      "8        Apple iPhone X (A1901)        3813\n",
      "9    Samsung Galaxy A5 Sm-A520F        3724\n"
     ]
    }
   ],
   "source": [
    "def getTopHandsets(num):\n",
    "    query = 'SELECT \"Handset Type\", count(*) as user_count FROM df3 WHERE \"Handset Type\" != \"undefined\" group by \"Handset Type\" order by user_count DESC LIMIT '+str(num)\n",
    "    return queryDf(query)\n",
    "\n",
    "def get_top_n(df, colname, num, globalDict):\n",
    "    queryDf = lambda q: sqldf(q, globalDict)\n",
    "    query = 'SELECT \"'+colname+'\", count(*) as user_count FROM '+df+' WHERE \"'+colname+'\" != \"undefined\" group by \"'+colname+'\" order by user_count DESC LIMIT '+str(num)\n",
    "    return queryDf(query)\n",
    "\n",
    "print(get_top_n('df','Handset Type',10,globals() ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be7d68c9-ad26-4200-9139-abdcdaa0329c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTopManu(num):\n",
    "    query = 'SELECT \"Handset Manufacturer\", count(*) as user_count FROM df3 WHERE \"Handset Type\" != \"undefined\" group by \"Handset Manufacturer\" order by user_count DESC LIMIT '+str(num)\n",
    "    return queryDf(query)\n",
    "print(getTopManu(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af86591-5c44-47af-9ab6-80657cbfd5ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def manByHandset(lis, dfname):\n",
    "    for man in lis:\n",
    "        query = 'SELECT \"Handset Manufacturer\", \"Handset Type\", count(*) as num_users \\\n",
    "        FROM '+dfname+'\\\n",
    "        WHERE \"Handset Manufacturer\" = \"'+man+'\" \\\n",
    "        group by \"Handset Type\" \\\n",
    "        order by num_users DESC \\\n",
    "        LIMIT 3'\n",
    "        print(queryDf(query),'\\n')\n",
    "        \n",
    "\n",
    "\n",
    "manByHandset(getTopManu(5)[\"Handset Manufacturer\"].to_list(),'df3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a7df23-fa07-4d9a-a7e1-09fe6ca8b534",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_agg(df, group_columns, agg_columns, agg_metrics, new_columns):\n",
    "    new_column_dict ={}\n",
    "    agg_dict = {}\n",
    "    for i in range(len(agg_columns)):\n",
    "        new_column_dict[agg_columns[i]] = new_columns[i]\n",
    "        agg_dict[agg_columns[i]] = agg_metrics[i]\n",
    "\n",
    "    new_df = df.groupby(group_columns).agg(agg_dict).reset_index().rename(columns=new_column_dict)\n",
    "    return new_df\n",
    "def combineColumns(df, col1, col2, new_name, rem=False):\n",
    "    df[new_name] = df[col1]+df[col2]\n",
    "    if(rem):\n",
    "        df.drop([col1, col2], axis = 1, inplace = True)\n",
    "\n",
    "grouping_lis = [\"MSISDN/Number\"]\n",
    "aggr_lis = [\"Bearer Id\", \"Dur. (ms)\", \"Total DL (Bytes)\", \"Total UL (Bytes)\", \"Social Media DL (Bytes)\", \"Social Media UL (Bytes)\",\\\n",
    "    \"Youtube DL (Bytes)\", \"Youtube UL (Bytes)\", \"Netflix DL (Bytes)\", \"Netflix UL (Bytes)\", \"Google DL (Bytes)\", \"Google UL (Bytes)\", \"Email DL (Bytes)\", \"Email UL (Bytes)\", \"Other DL (Bytes)\", \"Other UL (Bytes)\"] \n",
    "metric_lis = [\"count\", \"sum\", \"sum\", \"sum\", \"sum\", \"sum\", \"sum\", \"sum\",\"sum\", \"sum\", \"sum\", \"sum\", \"sum\", \"sum\", \"sum\",\"sum\"]\n",
    "col_names = [\"xDr_session_count\", \"session_dur\", \"Total_DL_sum\", \"Total_UL_sum\", \"Social_Media_DL_sum\", \"Social_Media_UL_sum\",\\\n",
    "    \"Youtube_DL_total\", \"Youtube_UL_total\", \"Netflix_DL_total\", \"Netflix_UL_total\", \"Google_DL_total\", \"Google_UL_total\", \"Email_DL_total\", \"Email_UL_total\", \"Other_DL_total\", \"Other_UL_total\"]\n",
    "\n",
    "\n",
    "aggr_df = find_agg(df, grouping_lis, aggr_lis, metric_lis, col_names)\n",
    "combineULDL(aggr_df, \"Youtube_DL_total\", \"Youtube_UL_total\")\n",
    "combineULDL(aggr_df, \"Netflix_DL_total\", \"Netflix_UL_total\")\n",
    "combineULDL(aggr_df, \"Google_DL_total\", \"Google_UL_total\")\n",
    "combineULDL(aggr_df, \"Email_DL_total\", \"Email_UL_total\")\n",
    "combineULDL(aggr_df, \"Social_Media_DL_sum\", \"Social_Media_UL_sum\")\n",
    "combineULDL(aggr_df, \"Other_DL_total\", \"Other_UL_total\")\n",
    "\n",
    "calculateMissing(aggr_df)\n",
    "\n",
    "aggr_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93869f69-af2b-4c43-a0dc-d06f920a0685",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_number(df, cols):\n",
    "    float_format_list = []\n",
    "\n",
    "    for i in range(cols.shape[0]):\n",
    "        if(cols.iloc[i,3] == \"float64\"):\n",
    "            float_format_list.append(cols.iloc[i,0])\n",
    "    for col in float_format_list:\n",
    "        df[col] = df.apply(lambda row : f'{row[col]:,.2f}', axis = 1)\n",
    "    \n",
    "    return df\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f38805eb-4cdf-43a2-b33f-6cf45bb22ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_bytes_to_megabytes(df, cols):\n",
    "    bytes_list = []\n",
    "    megabyte = 1*10e+5\n",
    "    \n",
    "    for i in range(cols.shape[0]):\n",
    "        if(\"(Bytes)\" in cols.iloc[i,0]):\n",
    "            bytes_list.append(cols.iloc[i,0])\n",
    "    \n",
    "    for col in bytes_list:\n",
    "        df[col] = df[col]/megabyte\n",
    "        df.rename(columns={col:col.replace('(Bytes)','(MB)')}, inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03895984-51d4-4213-9e3a-aeed33bc9ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = convert_bytes_to_megabytes(df3, calculateMissing(df3))\n",
    "calculateMissing(df3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea01acc5-c2ce-4e41-9daa-8d2f1c297bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "aggr_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02855812-e923-4e90-808e-510a22c4678f",
   "metadata": {},
   "source": [
    "<h2> Exploratory Data Analysis </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8cb7152-4c06-4986-aa40-8a9deca59d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating frequency tables.\n",
    "def generateFreqTable(df, cols):\n",
    "    for col in cols:\n",
    "        print(df[col].value_counts().head())\n",
    "        \n",
    "generateFreqTable(aggr_df, ['xDr_session_count', 'session_dur'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bcedbea-0f1d-4da6-b28e-7fd3e3485777",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summary_one(df, cols):\n",
    "    df2 = df[cols]\n",
    "    \n",
    "    df_sum = df2.max().to_frame().reset_index().rename(columns={\"index\":\"variables\",0:\"max\"})\n",
    "    df_sum[\"min\"] = df2.min().to_frame().reset_index().iloc[:,1]\n",
    "    df_sum['range'] = df_sum['max'] - df_sum['min']\n",
    "    df_sum[\"count\"] = df2.count().to_frame().reset_index().iloc[:,1]\n",
    "    return df_sum\n",
    "def summary_two(df, cols):\n",
    "    df2 = df[cols]\n",
    "    df_sum = df2.mean().to_frame().reset_index().rename(columns={\"index\":\"variables\",0:\"mean\"})\n",
    "    df_sum[\"median\"] = df2.median().to_frame().reset_index().iloc[:,1]\n",
    "    df_sum[\"mode\"] = df2.mode().iloc[:,1]\n",
    "    return df_sum\n",
    "def summary_three(df, cols):\n",
    "    df2 = df[cols]\n",
    "    df_sum = df2.std().to_frame().reset_index().rename(columns={\"index\":\"variables\",0:\"std\"})\n",
    "    df_sum[\"var\"] = df2.var().to_frame().reset_index().iloc[:,1]\n",
    "    return df_sum\n",
    "\n",
    "\n",
    "summary_one(aggr_df, ['xDr_session_count', 'session_dur'])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "041ee4c2-5f2f-456e-a59e-4c78d68423b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dipCat(df, cols):\n",
    "    plot_df = df[cols]\n",
    "    plt.figure(figsize=(25, 12))\n",
    "    sns.countplot(x=\"Handset Manufacturer\", data=plot_df.head())\n",
    "    \n",
    "dipCat(df3, ['Handset Type', 'Handset Manufacturer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "862d60cc-632a-42f3-b339-8c5705af91b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bivariateAnalysis(df, col , cols, crosst=False):\n",
    "    for col2 in cols:\n",
    "        df_plot = df[[col2, col]]\n",
    "        sns.relplot(data=df_plot, aspect = 2.0)\n",
    "        if(crosst):\n",
    "            pd.crosstab(df[col2], df[col], margins=True)\n",
    "    \n",
    "        \n",
    "aggr_df['Total_vol'] = aggr_df['Total_DL_sum'] + aggr_df['Total_UL_sum']\n",
    "com_list = ['Netflix_Total Vol_total', 'Google_Total Vol_total']\n",
    "bivariateAnalysis(aggr_df, 'Total_vol', com_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de462bf1-ff3c-4b5b-b910-6a1981ff8b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def topDecile(df, group, cols, metric, name, top=5):\n",
    "    aggr_n = find_agg(df, group, cols, metric, name)\n",
    "    aggr_n = aggr_n.loc[aggr_n['Decile'] < top+1]\n",
    "    return aggr_n\n",
    "\n",
    "aggr_df['Decile'] = pd.qcut(aggr_df['session_dur'], 10, labels=False)\n",
    "topDecile(aggr_df, ['Decile'], ['Total_vol'], ['sum'], ['Total_vol_p_decile'], 6 )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06533ee1-9812-4104-88b8-415d3d7db370",
   "metadata": {},
   "outputs": [],
   "source": [
    "def corrMatrix(df, cols):\n",
    "    relation = df[cols].corr()\n",
    "    return relation\n",
    "\n",
    "corrMatrix(aggr_df, ['Youtube_Total Vol_total', 'Google_Total Vol_total', 'Netflix_Total Vol_total'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0087c8c1-7434-49b5-8988-bb7479bcbc4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def low_variance_filter(df):\n",
    "    df.drop(['A'], axis = 1)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "adf5bc5e260c59b643027762308235212e9c91c47cf750b45ba00788ea37b167"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
